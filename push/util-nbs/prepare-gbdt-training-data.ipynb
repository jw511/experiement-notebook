{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45b280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import snrf\n",
    "import pushranker\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, DefaultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8433a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train/edition=en_US/push_type=scheduled/0516\n",
      "../data/test/edition=en_US/push_type=scheduled/0517\n"
     ]
    }
   ],
   "source": [
    "push_type = 'scheduled' # local, targeted, scheduled\n",
    "train_day = '0516'\n",
    "test_day = '0517'\n",
    "\n",
    "LOCAL_DATA_ROOT = Path('../data/')\n",
    "TRAIN_DATA_ROOT = str(LOCAL_DATA_ROOT / 'train' / 'edition=en_US' / f'push_type={push_type}' / train_day) # / 'dt=2021-04-30-00')\n",
    "TEST_DATA_ROOT = str(LOCAL_DATA_ROOT / 'test' / 'edition=en_US' / f'push_type={push_type}' / test_day) # / 'dt=2021-05-01-00')\n",
    "\n",
    "training_format = snrf.package.get_obj_from_name(pushranker, 'survival_feature_spec.binarized_format_devicetoken')\n",
    "\n",
    "# input_module = pushranker.local_push\n",
    "input_module = importlib.import_module(f'pushranker.{push_type}_push')\n",
    "\n",
    "print(TRAIN_DATA_ROOT)\n",
    "print(TEST_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4452884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare(root, shuffle=None):\n",
    "    ds = snrf.tfrecord.read_dataset_from_files(root)\n",
    "#     ds = ds.shuffle(10000)\n",
    "    ds = snrf.tfrecord.prepare_dataset_for_use(ds,\n",
    "                                               input_module.input_spec,\n",
    "                                               shuffle=shuffle,\n",
    "                                               training_format=training_format)\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare(TRAIN_DATA_ROOT, 10000)\n",
    "test_ds = prepare(TEST_DATA_ROOT)\n",
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab96db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform push-ranker data for GBDT\n",
    "numeric_features = ['predicted_ctr']\n",
    "dense_features = ['cgScores', 'a_stats', 'af_dense', 'uf_dense', 'u_hhs']\n",
    "dense_features_len = [10, 36, 9, 10, 24]\n",
    "# sparse_features = [\n",
    "#     'push_id', 'u_cate','u_catev2', 'u_hist_ids', 'u_pub', 'u_pub_ctr', 'u_kw',\n",
    "#     'a_catev2', 'a_features', 'a_site_id', 'a_kw', 'a_tw'\n",
    "# ]\n",
    "\n",
    "def build_numeric_feature(batch) -> List[float]:\n",
    "    samples = list()\n",
    "    i = 0\n",
    "    while True:\n",
    "        value = list()\n",
    "        try:\n",
    "            for f in numeric_features:\n",
    "                value.append(batch[0][f][i])\n",
    "        except IndexError:\n",
    "            break\n",
    "        else:\n",
    "            samples.append(value)\n",
    "            i += 1\n",
    "    return samples\n",
    "    \n",
    "\n",
    "def build_dense_feature(batch) -> List[List[float]]:\n",
    "    samples = list()\n",
    "    i = 0\n",
    "    while True:\n",
    "        feat_vec = list()\n",
    "        try:\n",
    "            for f in dense_features:\n",
    "                feat_vec.extend(list(batch[0][f][i]))\n",
    "        except IndexError:\n",
    "            break\n",
    "        else:\n",
    "            samples.append(feat_vec)\n",
    "            i += 1\n",
    "    return samples\n",
    "    \n",
    "\n",
    "def build_sparse_feature_dict(batch) -> List[Dict]:\n",
    "    samples = list()\n",
    "    i = 0\n",
    "    while True:\n",
    "        featureDict = dict()\n",
    "        try:\n",
    "            for f in sparse_features:\n",
    "                if f == 'push_id':\n",
    "                    featureDict[f] = str(batch[0][f][i])  \n",
    "                else:\n",
    "                    featureDict[f] = [str(val) for idx, val in np.ndenumerate(batch[0][f][i]) if val]       \n",
    "        except IndexError:\n",
    "            break\n",
    "        else:\n",
    "            samples.append(featureDict)\n",
    "            i += 1\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d104a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "numeric_feat = list()\n",
    "dense_feat = list()\n",
    "sparse_samples = list()\n",
    "\n",
    "for batch in train_ds.as_numpy_iterator():\n",
    "    numeric_feat.extend(build_numeric_feature(batch))\n",
    "    dense_feat.extend(build_dense_feature(batch))\n",
    "#     sparse_samples.extend(build_sparse_feature_dict(batch))\n",
    "    \n",
    "numeric_feature = np.array(numeric_feat)\n",
    "numeric_feat.clear()\n",
    "dense_feature = np.array(dense_feat)\n",
    "dense_feat.clear()\n",
    "# dense_feature_column = [f'{df}_{i}' for df, l in zip(dense_features, dense_features_len) for i in range(l)]\n",
    "\n",
    "# build sparse features transformer\n",
    "# vec = DictVectorizer()\n",
    "# sparse_feature = vec.fit_transform(sparse_samples).toarray()\n",
    "# sparse_samples.clear()\n",
    "# sparse_feature_column = vec.feature_names_\n",
    "# sparse_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5683229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35226290, 90)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge training data\n",
    "# feature_columns = numeric_features + dense_feature_column# + sparse_feature_column\n",
    "train_X = np.hstack((numeric_feature, dense_feature))#, sparse_feature))\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e420a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-trainX-{train_day}.npy'), train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a9515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36052789, 90)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare testing data\n",
    "numeric_feat = list()\n",
    "dense_feat = list()\n",
    "sparse_samples = list()\n",
    "for batch in test_ds.as_numpy_iterator():\n",
    "    numeric_feat.extend(build_numeric_feature(batch))\n",
    "    dense_feat.extend(build_dense_feature(batch))\n",
    "#     sparse_samples.extend(build_sparse_feature_dict(batch))\n",
    "numeric_feature = np.array(numeric_feat)\n",
    "numeric_feat.clear()\n",
    "dense_feature = np.array(dense_feat)\n",
    "dense_feat.clear()\n",
    "# sparse_feature = vec.transform(sparse_samples).toarray()\n",
    "# sparse_samples.clear()\n",
    "test_X = np.hstack((numeric_feature, dense_feature))#, sparse_feature))\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0be8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-testX-{test_day}.npy'), test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f20cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35226290\n",
      "36052789\n"
     ]
    }
   ],
   "source": [
    "# prepare labels\n",
    "train_y = list()\n",
    "test_y = list()\n",
    "\n",
    "for train in train_ds:\n",
    "    train_y.extend(list(np.array(train[1])))\n",
    "train_y = np.array(train_y)\n",
    "print(len(train_y))\n",
    "np.save(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-trainy-{train_day}.npy'), train_y)\n",
    "\n",
    "for test in test_ds:\n",
    "    test_y.extend(list(np.array(test[1])))\n",
    "test_y = np.array(test_y)\n",
    "print(len(test_y))\n",
    "np.save(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-testy-{test_day}.npy'), test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0e013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2149168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32d9dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e1376",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71dcd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-trainX-{train_day}.npy'))\n",
    "train_y = np.load(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-trainy-{train_day}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923f34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.load(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-testX-{test_day}.npy'))\n",
    "test_y = np.load(str(LOCAL_DATA_ROOT / 'gbdt' / f'{push_type}-testy-{test_day}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d0be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35226290, 90) (35226290,)\n",
      "(36052789, 90) (36052789,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd199c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCTRLabelDevtok(tfdata) -> Tuple[List]:\n",
    "    fy_gbdt_ctr = list()\n",
    "    label = list()\n",
    "    devtok = list()    \n",
    "\n",
    "    for feature_batch, label_batch, devtok_batch in tfdata.as_numpy_iterator():\n",
    "        for f, l, dtk in zip(feature_batch['predicted_ctr'], label_batch, devtok_batch):\n",
    "            fy_gbdt_ctr.append(f)\n",
    "            label.append(l)\n",
    "            devtok.append(dtk[0])\n",
    "    assert len(fy_gbdt_ctr) == len(label) == len(devtok)\n",
    "    return fy_gbdt_ctr, label, devtok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7293dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46min 8s, sys: 52.9 s, total: 47min 1s\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import concurrent.futures\n",
    "\n",
    "tfdata = [train_ds, test_ds]\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     future = executor.submit(getCTRLabelDevtok, train_ds)\n",
    "#     return_value = future.result()\n",
    "    futures = [executor.submit(getCTRLabelDevtok, param) for param in tfdata]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f39f4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 9s, sys: 46.1 s, total: 45min 55s\n",
      "Wall time: 22min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for d in tfdata:\n",
    "    a, b, c = getCTRLabelDevtok(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59a8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fy_gbdt_ctr, train_label, train_devtok = futures[0].result()\n",
    "test_fy_gbdt_ctr, test_label, test_devtok = futures[1].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42c9074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35226290\n",
      "2149168\n"
     ]
    }
   ],
   "source": [
    "print(len(train_label)) #examples\n",
    "print(sum(train_label)) #pos examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc42f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36052789\n",
      "2501688\n"
     ]
    }
   ],
   "source": [
    "print(len(test_label))\n",
    "print(sum(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f7aaf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15236203\n",
      "15313733\n",
      "13707402\n",
      "CPU times: user 20.9 s, sys: 1.31 s, total: 22.2 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# user cnt\n",
    "distUsers_train = set(train_devtok)\n",
    "print(len(distUsers_train))\n",
    "distUsers_test = set(test_devtok)\n",
    "print(len(distUsers_test))\n",
    "\n",
    "interUsers = set.intersection(distUsers_train, distUsers_test)\n",
    "print(len(interUsers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769451ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 6s, sys: 7.27 s, total: 7min 14s\n",
      "Wall time: 7min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import collections\n",
    "# from itertools import repeat\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "len_samples_train = len(train_devtok)\n",
    "len_samples_test = len(test_devtok)\n",
    "user_fy_gbdt_train = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "user_fy_gbdt_test = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "def getScoreLabel(i: int, user_fy_gbdt: DefaultDict):\n",
    "    user_fy_gbdt[devtok[i]].append((fy_gbdt_ctr[i], label[i]))\n",
    "    \n",
    "# num_processors = 32\n",
    "# p = Pool(processes=num_processors)\n",
    "# p.starmap(getScoreLabel, zip(range(len_samples), repeat(user_fy_gbdt)))\n",
    "# p.close()\n",
    "\n",
    "# train\n",
    "for i in range(len_samples_train):\n",
    "    user_fy_gbdt_train[train_devtok[i]]['score'].append(train_fy_gbdt_ctr[i])\n",
    "    user_fy_gbdt_train[train_devtok[i]]['label'].append(train_label[i])\n",
    "\n",
    "# test\n",
    "for i in range(len_samples_test):\n",
    "    user_fy_gbdt_test[test_devtok[i]]['score'].append(test_fy_gbdt_ctr[i])\n",
    "    user_fy_gbdt_test[test_devtok[i]]['label'].append(test_label[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f3bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "# # #users have more than one news and at least one positive example\n",
    "\n",
    "# def moreThanOneNewsAndAtLeastOnePositive(newsList: List) -> int:\n",
    "#     return 1 if len(newsList) > 1 and sum(l for _, l in newsList) > 0 else 0\n",
    "\n",
    "# num_processors = 32\n",
    "# p = Pool(processes=num_processors)\n",
    "# r = p.map(moreThanOneNewsAndAtLeastOnePositive, user_fy_gbdt.values())\n",
    "# sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7647bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 0 ns, total: 13.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "991764"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = sum(1 for news in user_fy_gbdt_test.values() if (len(news['label']) > 1) and sum(news['label'])>0)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "## candidates distribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
